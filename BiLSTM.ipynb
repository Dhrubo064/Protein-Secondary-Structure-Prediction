{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12236095,
          "sourceType": "datasetVersion",
          "datasetId": 7709726
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcE6D5K7pL85",
        "outputId": "097bd362-1346-4980-82e1-727bfa36fe92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "oI9gZTzIpL_Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pss_data = pd.read_csv('/content/subset_file_50000_100000.csv')\n",
        "\n",
        "# Display first few rows of the dataset\n",
        "pss_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "kTNODOhnpMB5",
        "outputId": "c4244611-7ff6-4c2f-e0c0-80d83b259790"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  pdb_id chain_code                                                seq  \\\n",
              "0   5XFV          A  MAHHHHHHSAALEVLFQGPGSMSLKVNILGHEFSNPFMNAAGVLCT...   \n",
              "1   4R9X          A  MLEVIATCLEDVKRIERAGGKRIELISSYTEGGLTPSYAFIKKAVE...   \n",
              "2   5VAX          A  GSMAHAGRTGYDNREIVMKYIHYKLSQRGYEWDDGDDVEENRTEAP...   \n",
              "3   5LSJ          D  MGTLQKCFEDSNGKASDFSLEASVAEMKEYITKFSLERQTWDQLLL...   \n",
              "4   2J5I          B  MSTYEGRWKTVKVEIEDGIAFVILNRPEKRNAMSPTLNREMIDVLE...   \n",
              "\n",
              "                                                sst8  \\\n",
              "0  CCCCCCCCCCCCCCCCCCCCCCCCCEEETTEEESSSEEECTTSSCS...   \n",
              "1  CEEEEESSHHHHHHHHHTTCCEEEECBCGGGTCBCCCHHHHHHHHH...   \n",
              "2  CCCCCCCCCCCCHHHHHHHHHHHHHHTTTCCCCCCCCCCCCCCCCC...   \n",
              "3  CCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHH...   \n",
              "4  CCCCCCCCSSEEEEEETTEEEEEECCGGGTTCBCHHHHHHHHHHHH...   \n",
              "\n",
              "                                                sst3  len  has_nonstd_aa  \n",
              "0  CCCCCCCCCCCCCCCCCCCCCCCCCEEECCEEECCCEEECCCCCCC...  334          False  \n",
              "1  CEEEEECCHHHHHHHHHCCCCEEEECECHHHCCECCCHHHHHHHHH...  233          False  \n",
              "2  CCCCCCCCCCCCHHHHHHHHHHHHHHCCCCCCCCCCCCCCCCCCCC...  168          False  \n",
              "3  CCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHH...  178          False  \n",
              "4  CCCCCCCCCCEEEEEECCEEEEEECCHHHCCCECHHHHHHHHHHHH...  276          False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53d37fc3-5202-4f01-a4fc-103f1f2ff868\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdb_id</th>\n",
              "      <th>chain_code</th>\n",
              "      <th>seq</th>\n",
              "      <th>sst8</th>\n",
              "      <th>sst3</th>\n",
              "      <th>len</th>\n",
              "      <th>has_nonstd_aa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5XFV</td>\n",
              "      <td>A</td>\n",
              "      <td>MAHHHHHHSAALEVLFQGPGSMSLKVNILGHEFSNPFMNAAGVLCT...</td>\n",
              "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCEEETTEEESSSEEECTTSSCS...</td>\n",
              "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCEEECCEEECCCEEECCCCCCC...</td>\n",
              "      <td>334</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4R9X</td>\n",
              "      <td>A</td>\n",
              "      <td>MLEVIATCLEDVKRIERAGGKRIELISSYTEGGLTPSYAFIKKAVE...</td>\n",
              "      <td>CEEEEESSHHHHHHHHHTTCCEEEECBCGGGTCBCCCHHHHHHHHH...</td>\n",
              "      <td>CEEEEECCHHHHHHHHHCCCCEEEECECHHHCCECCCHHHHHHHHH...</td>\n",
              "      <td>233</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5VAX</td>\n",
              "      <td>A</td>\n",
              "      <td>GSMAHAGRTGYDNREIVMKYIHYKLSQRGYEWDDGDDVEENRTEAP...</td>\n",
              "      <td>CCCCCCCCCCCCHHHHHHHHHHHHHHTTTCCCCCCCCCCCCCCCCC...</td>\n",
              "      <td>CCCCCCCCCCCCHHHHHHHHHHHHHHCCCCCCCCCCCCCCCCCCCC...</td>\n",
              "      <td>168</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5LSJ</td>\n",
              "      <td>D</td>\n",
              "      <td>MGTLQKCFEDSNGKASDFSLEASVAEMKEYITKFSLERQTWDQLLL...</td>\n",
              "      <td>CCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHH...</td>\n",
              "      <td>CCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHH...</td>\n",
              "      <td>178</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2J5I</td>\n",
              "      <td>B</td>\n",
              "      <td>MSTYEGRWKTVKVEIEDGIAFVILNRPEKRNAMSPTLNREMIDVLE...</td>\n",
              "      <td>CCCCCCCCSSEEEEEETTEEEEEECCGGGTTCBCHHHHHHHHHHHH...</td>\n",
              "      <td>CCCCCCCCCCEEEEEECCEEEEEECCHHHCCCECHHHHHHHHHHHH...</td>\n",
              "      <td>276</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53d37fc3-5202-4f01-a4fc-103f1f2ff868')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53d37fc3-5202-4f01-a4fc-103f1f2ff868 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53d37fc3-5202-4f01-a4fc-103f1f2ff868');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d753d7e1-c9d2-45b1-9d18-ebbf34bdd64f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d753d7e1-c9d2-45b1-9d18-ebbf34bdd64f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d753d7e1-c9d2-45b1-9d18-ebbf34bdd64f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pss_data",
              "summary": "{\n  \"name\": \"pss_data\",\n  \"rows\": 44967,\n  \"fields\": [\n    {\n      \"column\": \"pdb_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40770,\n        \"samples\": [\n          \"1BE3\",\n          \"4GJY\",\n          \"2ID1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 62,\n        \"samples\": [\n          \"V\",\n          \"s\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seq\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44967,\n        \"samples\": [\n          \"QVQLVESGGGLVQAGGSLRLSCAASGRTFSSYGMGWFRQAPGKEREFVAAIRWNGGSTYYADSVKGRFTISRDNAKNTVYLQMNSLKPEDTAVYYCAAGRWDKYGSSFQDEYDYWGQGTQVTVSSHHHHHH\",\n          \"MSPILAKNIVYVAQIKGQITSYTYDQFDRYITIAEQDNAEAIIIELDTPGGRADAMMNIVQRIQQSKIPVIIYVYPPGASAASAGTYIALGSHLIAMAPGTSIGACRPILGYSQNGSIIEAPPAITNYFIAYIKSLAQESGRNATIAEEFITKDLSLTPEEALKYGVIEVVARDINELLKKSNGMKTKIPVNGRYVTLNFTNVEVRYLAPSFKDKLISYITDLEHHHHHH\",\n          \"ATCDDGRTTANAACCILFPILDDIQENLFDGAQCGEEVHESLRLTFHDAIGFSPTLGGGGADGSIIAFDTIETNFPANAGIDEIVSAQKPFVAKHNISAGDFIQFAGAVGVSNCPGGVRIPFFLGRPDAVAASPDHLVPEPFDSVDSILARMGDAGFSPVEVVWLLASHSIAAADKVDPSIPGTPFDSTPGVFDSQFFIETQLKGRLFPGTADNKGEAQSPLQGEIRLQSDHLLARDPQTACEWQSMVNNQPKIQNRFAATMSKMALLGQDKTKLIDCSDVIPTPPALVGAAHLPAGFSLSDVEQACAATPFPALTADPGPVTSVPPVPGS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sst8\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44441,\n        \"samples\": [\n          \"CCSCTTEEEEECSCCSSCEEEEECSSCCCBSEEEEEEEEECCSCTTSCEEEEEEEETTEEEEEEEECTTSCEEEEESCSSCEEEECCCCCCSSCEEEEEEEETTTCEEEEEETTEECCCEECSTTCCBCSSCEEEESSCGGGCSSSCCGGGCCCEEEEEEEEESSCCCHHHHHHHHTTCTTCCCCSSEETTTCEEEEESSCEEEECC\",\n          \"CCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHCTTHHHHCCHHHHHHHHHHHHHHHHHHSCCCTTSCCCCCCCHHHHHHHHHHHHHHHHHHHHTCCCCCCCCCCCCCCCCCCCCCCCEECCCCSCCCCCCTTCGGGCCCCSTTTTSCSCEEGGGCCGGGTCCSCTTSHHHHHHHHHHHHHHHHTTCHHHHHHHHHHHHHHTTCCHHHHHHHHHHHHHHTTSHHHHTTCSCCSSTTCCHHHHHHHHHTTCCTGGGCCTTTHHHHHHHHHHHHHHHTTCCGGGCCCHHHHCCC\",\n          \"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHSCCCCCCCGGGEEEEEEEEECSSCEEEEEEETTTCCEEEEEEEEHHHHHHTTCHHHHHHHHHHHTTCCCTTBCCEEEEEECSSEEEEEEECCTTCBHHHHHHHHCCCCHHHHHHHHHHHHHHHHHHHHTTEECCCCSGGGEEECTTSCEEECCCTTCEECSSCBCCCCBCGGGCCHHHHTTCCBCTHHHHHHHHHHHHHHHHSSCSSCCSSHHHHHHHHHHTCCCCCTTSCHHHHHHHHHHSCSCTTTSTTSSTTTTHHHHTSGGGTTCCHHHHHTTCSCCSCCCCCCSTTCCTTSCCCCCCCCCCCSSCCSTTTTTTC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sst3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43723,\n        \"samples\": [\n          \"CCCCCCCCCCCCCCCEEEEECCCCCCCHHHHHHHHHHHCCCEEEEEECHHHHHHHHHHHHCCCCHHHHECCCCCECCEEEEEECCCCCCCHHHCCHHHHCCHHHHCCCCCCHHHHHHHHHHHHCCEEEEEECCCCCCCCCCCHHHCCHHHHHHHHHHHCHHHHHHHHHHHHHEEEEEEEEEEECHHHCCECCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCEEEEEEECCCCCHHHHHCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHCCCCCCCCHHHHHHHHHHHHCHHHCCCCCCEEEECCCHHHECCCCCCCCCCCC\",\n          \"CCCCCCCCCCCCHHHHHHHHCCCEEEEEECCCCCCCCCCCCHHHHHHHHHHHCCCCCCCCHHHHHHHHHHHHHCCCCCCCCCCCCCEEECCCCCCCCCCCCEECCEECEEEEEEEEECCCCCEEEEEEECCCCCCCCCCCCCCCCCCCCC\",\n          \"CCCCCCEEEEEEEECCCHHHHCCCCCHHHHHHHHHCCCCCCCCCCCCHHHCCHHHHHHHHHHHHHHHHHHHHHHCCCCCCEEEEEEECCCCEEEEEEEECCCCCHHHHHHHHHHHHHHHHHHCCCCCCCCCCCCEEECECCCCCCCCECCECCCHHHHHCCCCCCCCEEEEEECCHHHCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111,\n        \"min\": 50,\n        \"max\": 500,\n        \"num_unique_values\": 451,\n        \"samples\": [\n          61,\n          335,\n          377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_nonstd_aa\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmention by oversampling the minority class\n",
        "# Separate the dataset into different classes\n",
        "# coil_data = pss_data[pss_data['sst3'] == 'C']\n",
        "# sheet_data = pss_data[pss_data['sst3'] == 'E']\n",
        "# helix_data = pss_data[pss_data['sst3'] == 'H']\n",
        "\n",
        "# Determine the maximum count among the classes (the majority class)\n",
        "# max_class_size = max(coil_data.shape[0], sheet_data.shape[0], helix_data.shape[0])\n",
        "\n",
        "# Oversample the minority classes to match the size of the majority class\n",
        "# Check if the dataframes are not empty before sampling\n",
        "# sheet_data_oversampled = sheet_data.sample(max_class_size, replace=True, random_state=42) if not sheet_data.empty else pd.DataFrame(columns=sheet_data.columns)\n",
        "# helix_data_oversampled = helix_data.sample(max_class_size, replace=True, random_state=42) if not helix_data.empty else pd.DataFrame(columns=helix_data.columns)\n",
        "\n",
        "# Combine the data back into one balanced dataset\n",
        "# balanced_data = pd.concat([coil_data, sheet_data_oversampled, helix_data_oversampled])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "# balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Display the new class distribution\n",
        "# balanced_distribution = balanced_data['sst3'].value_counts()\n",
        "# print(balanced_distribution)\n",
        "\n",
        "# Removed data augmentation as it was causing issues with empty dataframes.\n",
        "# Proceeding with original data split.\n",
        "print(\"Data augmentation step removed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzx-b9WBpMEQ",
        "outputId": "d268e188-1642-4ebb-bbd1-03027c117a35"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation step removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pss_data_cleaned = pss_data.dropna(subset=['sst3'])\n",
        "\n",
        "X = pss_data_cleaned['seq']  # Amino acid sequence\n",
        "y = pss_data_cleaned['sst3']  # Secondary structure labels (C, E, H)\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(val_texts, val_labels, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "PhGVjgR1pMGg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Tokenizer (We won't use a pre-trained model, just padding and truncation)\n",
        "def tokenize_data(texts, max_length=128):\n",
        "    # Convert sequences into tokenized format (just numeric encoding here)\n",
        "    tokenized_texts = []\n",
        "    for seq in texts:\n",
        "        # Use ASCII value for each amino acid as tokens\n",
        "        tokenized_seq = [ord(c) for c in seq]\n",
        "        # Pad or truncate the sequence to max_length\n",
        "        if len(tokenized_seq) > max_length:\n",
        "            tokenized_seq = tokenized_seq[:max_length]\n",
        "        elif len(tokenized_seq) < max_length:\n",
        "            tokenized_seq = tokenized_seq + [0] * (max_length - len(tokenized_seq)) # Pad with 0\n",
        "\n",
        "        tokenized_texts.append(tokenized_seq)\n",
        "    return tokenized_texts\n",
        "\n",
        "# Define label map\n",
        "label_map = {'C': 0, 'E': 1, 'H': 2}\n",
        "\n",
        "# Filter sequences and labels simultaneously, character by character\n",
        "def filter_data(texts, labels, label_map, max_length=128):\n",
        "    filtered_texts = []\n",
        "    filtered_labels = []\n",
        "    for text, label_seq in zip(texts, labels):\n",
        "        filtered_text_seq = []\n",
        "        filtered_label_seq = []\n",
        "        for i in range(min(len(text), len(label_seq), max_length)):\n",
        "            if label_seq[i] in label_map:\n",
        "                filtered_text_seq.append(ord(text[i]))\n",
        "                filtered_label_seq.append(label_map[label_seq[i]])\n",
        "\n",
        "        if filtered_text_seq: # Only add if there are valid tokens after filtering\n",
        "            # Pad or truncate the filtered sequence and labels\n",
        "            if len(filtered_text_seq) < max_length:\n",
        "                filtered_text_seq += [0] * (max_length - len(filtered_text_seq))\n",
        "                filtered_label_seq += [-100] * (max_length - len(filtered_label_seq)) # Use -100 for padding labels\n",
        "            elif len(filtered_text_seq) > max_length:\n",
        "                filtered_text_seq = filtered_text_seq[:max_length]\n",
        "                filtered_label_seq = filtered_label_seq[:max_length]\n",
        "\n",
        "            filtered_texts.append(filtered_text_seq)\n",
        "            filtered_labels.append(filtered_label_seq)\n",
        "\n",
        "    return filtered_texts, filtered_labels\n",
        "\n",
        "\n",
        "# Filter the datasets\n",
        "train_encodings, train_labels_filtered = filter_data(train_texts, train_labels, label_map)\n",
        "val_encodings, val_labels_filtered = filter_data(val_texts, val_labels, label_map)\n",
        "test_encodings, test_labels_filtered = filter_data(test_texts, test_labels, label_map)\n",
        "\n",
        "\n",
        "# Print sizes after filtering and tokenization\n",
        "print(f\"Size of train_encodings: {len(train_encodings)}\")\n",
        "print(f\"Size of train_labels_filtered: {len(train_labels_filtered)}\")\n",
        "print(f\"Size of val_encodings: {len(val_encodings)}\")\n",
        "print(f\"Size of val_labels_filtered: {len(val_labels_filtered)}\")\n",
        "print(f\"Size of test_encodings: {len(test_encodings)}\")\n",
        "print(f\"Size of test_labels_filtered: {len(test_labels_filtered)}\")\n",
        "\n",
        "\n",
        "# Convert the data into Hugging Face Dataset format with torch tensors\n",
        "# Rename columns to match Trainer's expected input names\n",
        "train_data = Dataset.from_dict({\n",
        "    \"input_ids\": torch.tensor(train_encodings),\n",
        "    \"labels\": torch.tensor(train_labels_filtered, dtype=torch.long),\n",
        "})\n",
        "\n",
        "val_data = Dataset.from_dict({\n",
        "    \"input_ids\": torch.tensor(val_encodings),\n",
        "    \"labels\": torch.tensor(val_labels_filtered, dtype=torch.long),\n",
        "})\n",
        "\n",
        "test_data = Dataset.from_dict({\n",
        "    \"input_ids\": torch.tensor(test_encodings),\n",
        "    \"labels\": torch.tensor(test_labels_filtered, dtype=torch.long),\n",
        "})\n",
        "\n",
        "# Print sizes of the created datasets\n",
        "print(f\"Size of train_data: {len(train_data)}\")\n",
        "print(f\"Size of val_data: {len(val_data)}\")\n",
        "print(f\"Size of test_data: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eirNimdpMIz",
        "outputId": "4e877ac9-9dca-4e89-d41e-5cd735a7befa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train_encodings: 35973\n",
            "Size of train_labels_filtered: 35973\n",
            "Size of val_encodings: 4497\n",
            "Size of val_labels_filtered: 4497\n",
            "Size of test_encodings: 4497\n",
            "Size of test_labels_filtered: 4497\n",
            "Size of train_data: 35973\n",
            "Size of val_data: 4497\n",
            "Size of test_data: 4497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BiLSTM Model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers=2, dropout=0.5):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=n_layers, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # *2 for bidirectional\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, labels=None): # Modify forward method\n",
        "        embedded = self.dropout(self.embedding(input_ids))\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        output = self.fc(lstm_out)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            # Adjust dimensions for loss calculation\n",
        "            # Flatten the output and labels for CrossEntropyLoss\n",
        "            loss = loss_fct(output.view(-1, self.fc.out_features), labels.view(-1))\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": output} # Return dictionary"
      ],
      "metadata": {
        "id": "52GFcWWspMLJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BiLSTM model\n",
        "model = BiLSTM(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bilstm_output\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False, # Add this line\n",
        ")"
      ],
      "metadata": {
        "id": "al_P0hbbpMNS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define the compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Flatten the predictions and labels and remove padding (label -100)\n",
        "    flat_predictions = predictions.flatten()\n",
        "    flat_labels = labels.flatten()\n",
        "\n",
        "    # Compute Accuracy, Precision, Recall, F1, and Macro F1 on filtered data\n",
        "    accuracy = accuracy_metric.compute(predictions=flat_predictions, references=flat_labels)\n",
        "    precision = precision_metric.compute(predictions=flat_predictions, references=flat_labels, average=\"weighted\")\n",
        "    recall = recall_metric.compute(predictions=flat_predictions, references=flat_labels, average=\"weighted\")\n",
        "    f1 = f1_metric.compute(predictions=flat_predictions, references=flat_labels, average=\"weighted\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy[\"accuracy\"],\n",
        "        \"precision\": precision[\"precision\"],\n",
        "        \"recall\": recall[\"recall\"],\n",
        "        \"f1\": f1[\"f1\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "QPkI1erZpMPn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer with BiLSTM model\n",
        "\n",
        "# Print the size of the training dataset\n",
        "print(f\"Size of training dataset: {len(train_data)}\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "K8qytJPHpMR8",
        "outputId": "d2ecec8d-f067-4f87-d508-01eeb76dbf3b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training dataset: 35973\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8996' max='8996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8996/8996 03:05, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.996900</td>\n",
              "      <td>1.004649</td>\n",
              "      <td>0.471175</td>\n",
              "      <td>0.432652</td>\n",
              "      <td>0.471175</td>\n",
              "      <td>0.445504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.997800</td>\n",
              "      <td>1.004038</td>\n",
              "      <td>0.471884</td>\n",
              "      <td>0.434962</td>\n",
              "      <td>0.471884</td>\n",
              "      <td>0.444616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.999700</td>\n",
              "      <td>1.001982</td>\n",
              "      <td>0.471695</td>\n",
              "      <td>0.434599</td>\n",
              "      <td>0.471695</td>\n",
              "      <td>0.445352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.994800</td>\n",
              "      <td>1.001244</td>\n",
              "      <td>0.471941</td>\n",
              "      <td>0.434986</td>\n",
              "      <td>0.471941</td>\n",
              "      <td>0.445737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8996, training_loss=0.9985389431724022, metrics={'train_runtime': 185.6489, 'train_samples_per_second': 775.076, 'train_steps_per_second': 48.457, 'total_flos': 0.0, 'train_loss': 0.9985389431724022, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "0210c087",
        "outputId": "c69b4e24-ed92-4a68-dab9-93c4aee68322"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the model on the test data using the trainer's evaluate method\n",
        "eval_results = trainer.evaluate(test_data)\n",
        "\n",
        "# The eval_results dictionary contains the metrics calculated by compute_metrics, including Q3 accuracy and f1\n",
        "q3_accuracy = eval_results[\"eval_accuracy\"]\n",
        "f1_score = eval_results[\"eval_f1\"]\n",
        "\n",
        "# To get the classification report, we need the flattened, non-padded true and predicted labels from the test set\n",
        "# We can get the predictions and labels using trainer.predict and then filter\n",
        "predictions = trainer.predict(test_data)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Flatten and filter out padding (-100)\n",
        "flat_predicted_labels = predicted_labels.flatten()\n",
        "flat_true_labels = true_labels.flatten()\n",
        "\n",
        "mask = flat_true_labels != -100\n",
        "filtered_predicted_labels = flat_predicted_labels[mask]\n",
        "filtered_true_labels = flat_true_labels[mask]\n",
        "\n",
        "\n",
        "# Print Q3 accuracy and F1 score\n",
        "print(\"Q3 Accuracy: {:.4f}\".format(q3_accuracy))\n",
        "print(\"Weighted F1 Score: {:.4f}\".format(f1_score))\n",
        "\n",
        "\n",
        "# Print classification report\n",
        "# Define target names based on your label_map\n",
        "target_names = [\"Coil\", \"Sheet\", \"Helix\"] # Assuming 0: Coil, 1: Sheet, 2: Helix\n",
        "# Explicitly specify the labels to report on\n",
        "report_labels = [0, 1, 2] # Corresponding to Coil, Sheet, Helix\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(filtered_true_labels, filtered_predicted_labels, labels=report_labels, target_names=target_names))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q3 Accuracy: 0.4730\n",
            "Weighted F1 Score: 0.4467\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Coil       0.56      0.69      0.62    247790\n",
            "       Sheet       0.40      0.32      0.36    126776\n",
            "       Helix       0.44      0.37      0.40    168294\n",
            "\n",
            "    accuracy                           0.50    542860\n",
            "   macro avg       0.47      0.46      0.46    542860\n",
            "weighted avg       0.49      0.50      0.49    542860\n",
            "\n"
          ]
        }
      ]
    }
  ]
}